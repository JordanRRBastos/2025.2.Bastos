{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeT15dkWDIBQ"
      },
      "outputs": [],
      "source": [
        "# --- 1° Passo para o TCC Configuração e Importação de Bibliotecas ---\n",
        "\n",
        "# Instalação de bibliotecas (necessário no Google Colab, pode pular se já tiver instalado localmente)\n",
        "!pip install pandas scikit-learn joblib lightgbm openpyxl matplotlib seaborn\n",
        "\n",
        "# Importação das bibliotecas\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier # Algoritmo de exemplo: RandomForest\n",
        "# from lightgbm import LGBMClassifier # Descomente e use se preferir LightGBM\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "import joblib # Para salvar e carregar o pipeline\n",
        "\n",
        "# Para visualização da matriz de confusão\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Para upload e leitura de .xlsx no Colab\n",
        "from google.colab import files\n",
        "import io\n",
        "import os # Para lidar com caminhos de arquivo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2° Passo para o TCC Upload do XLSX e Carregamento dos Dados ---\n",
        "\n",
        "print(\"Por favor, faça o upload do seu arquivo XLSX (treinoML.xlsx):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Obtém o nome do primeiro (e geralmente único) arquivo enviado\n",
        "# Substitua 'relatorio_bi_certificados_04-07-2025.xlsx' pelo nome do seu arquivo XLSX se for diferente\n",
        "# Ou use file_name = list(uploaded.keys())[0] para pegar o nome automaticamente\n",
        "XLSX_FILE_NAME = 'treinoML.xlsx' # Ajuste este nome para o seu arquivo, se necessário\n",
        "\n",
        "# Carregar os dados do arquivo XLSX\n",
        "print(f\"\\nCarregando dados de '{XLSX_FILE_NAME}'...\")\n",
        "try:\n",
        "    df = pd.read_excel(io.BytesIO(uploaded[XLSX_FILE_NAME]), engine='openpyxl')\n",
        "    print(\"Dados carregados com sucesso!\")\n",
        "    print(f\"Shape dos dados: {df.shape}\")\n",
        "    print(\"Primeiras 5 linhas:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nInformações sobre as colunas:\")\n",
        "    df.info()\n",
        "except KeyError:\n",
        "    print(f\"ERRO: O arquivo '{XLSX_FILE_NAME}' não foi encontrado entre os arquivos enviados.\")\n",
        "    print(\"Verifique se o nome do arquivo no código (XLSX_FILE_NAME) corresponde ao nome do arquivo que você fez upload.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"ERRO ao carregar o arquivo XLSX: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "a308kTzTDf-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3° Passo para o TCC Definição de Features, Alvo e Tratamento de Nulos --\n",
        "# --- Configurações de Colunas para o Python ---\n",
        "TARGET_COLUMN = 'SLA_Atrasado_3Dias'\n",
        "\n",
        "NUMERICAL_FEATURES = [\n",
        ".\n",
        "    # ADICIONE AQUI TODAS AS SUAS OUTRAS COLUNAS NUMÉRICAS\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = [\n",
        ".\n",
        ".\n",
        "    # ADICIONE AQUI TODAS AS SUAS OUTRAS COLUNAS DE TEXTO\n",
        "]\n",
        "\n",
        "# --- Verificações e Preparação de X (Features) e y (Alvo) ---\n",
        "if TARGET_COLUMN not in df.columns:\n",
        "    raise ValueError(f\"A coluna alvo '{TARGET_COLUMN}' não foi encontrada no DataFrame. Verifique o nome da coluna no seu XLSX.\")\n",
        "\n",
        "# Converte a coluna alvo para int, preenchendo nulos com 0 (isso foi feito no PQ, mas reconfirma)\n",
        "# No entanto, para TREINAMENTO, queremos que os 'null's no alvo sejam removidos!\n",
        "# Vamos converter para float primeiro para aceitar NaN temporariamente.\n",
        "df[TARGET_COLUMN] = df[TARGET_COLUMN].fillna(-1) # Placeholder temporário para nulos\n",
        "df[TARGET_COLUMN] = df[TARGET_COLUMN].astype(int)\n",
        "\n",
        "# --- REMOVER LINHAS ONDE A COLUNA ALVO É NULA (tickets abertos) PARA O TREINAMENTO ---\n",
        "# O modelo APENAS aprenderá com tickets que foram CONCLUÍDOS e cujo SLA é conhecido (0 ou 1).\n",
        "initial_rows = df.shape[0]\n",
        "df_train = df[df[TARGET_COLUMN] != -1].copy() # Filtra as linhas com placeholder\n",
        "removed_rows = initial_rows - df_train.shape[0]\n",
        "print(f\"\\nRemovidas {removed_rows} linhas do treinamento (tickets em aberto ou com dados incompletos para o alvo).\")\n",
        "\n",
        "if df_train.empty:\n",
        "    raise ValueError(\"Não há dados suficientes para treinar o modelo após remover linhas com alvo nulo.\")\n",
        "\n",
        "X = df_train[NUMERICAL_FEATURES + CATEGORICAL_FEATURES].copy()\n",
        "y = df_train[TARGET_COLUMN].copy()\n",
        "\n",
        "\n",
        "# --- Tratamento de Valores Nulos nas FEATURES (IMPORTANTE!) ---\n",
        "print(\"\\nVerificando e tratando valores nulos nas FEATURES para o TREINAMENTO:\")\n",
        "for col in NUMERICAL_FEATURES:\n",
        "    if X[col].isnull().any():\n",
        "        median_val = X[col].median()\n",
        "        X[col] = X[col].fillna(median_val)\n",
        "        print(f\"  Preenchidos nulos na coluna numérica '{col}' com a mediana ({median_val:.2f}).\")\n",
        "\n",
        "for col in CATEGORICAL_FEATURES:\n",
        "    if X[col].isnull().any():\n",
        "        X[col] = X[col].fillna('Desconhecido')\n",
        "        print(f\"  Preenchidos nulos na coluna categórica '{col}' com 'Desconhecido'.\")\n",
        "\n",
        "print(\"\\nStatus de nulos nas FEATURES após tratamento (espera-se 0 nulos):\")\n",
        "print(X.isnull().sum())\n",
        "if X.isnull().sum().sum() > 0:\n",
        "    print(\"AVISO: Ainda existem valores nulos nas features após o tratamento. Verifique os dados.\")"
      ],
      "metadata": {
        "id": "GX5M46lRD8lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  4° Passo para o TCC Criação do Pipeline de Pré-processamento e Modelo ---\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', NUMERICAL_FEATURES),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), CATEGORICAL_FEATURES)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "# Opcional: Para LightGBM\n",
        "# import lightgbm as lgb\n",
        "# classifier = lgb.LGBMClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "print(\"\\nPipeline de ML criado com sucesso!\")\n",
        "print(model_pipeline)"
      ],
      "metadata": {
        "id": "1j8MbtZ-EQpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5° Passo para o TCC Divisão dos Dados e Treinamento do Pipeline ---\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"\\nDados divididos: Treino={X_train.shape}, Teste={X_test.shape}\")\n",
        "\n",
        "print(\"\\nIniciando treinamento do modelo...\")\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "print(\"Treinamento concluído!\")"
      ],
      "metadata": {
        "id": "BbMod5x9EUaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6° Passo para o TCC Avaliação do Modelo ---\n",
        "\n",
        "print(\"\\nAvaliação do Modelo no Conjunto de Teste:\")\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "y_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"Acurácia: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"AUC (Area Under the Curve): {roc_auc_score(y_test, y_proba):.4f}\")\n",
        "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "eFIuSN7zEaBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  Matriz de Confusão Visual ---\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "class_names = ['Dentro do SLA (0)', 'Atrasado (1)']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "plt.title('Matriz de Confusão - Previsão de Atraso de SLA')\n",
        "plt.ylabel('Valores Reais')\n",
        "plt.xlabel('Previsões do Modelo')\n",
        "\n",
        "# Anotações para TCC\n",
        "# TN: Verdadeiro Negativo (Previu 0, Real 0) - Acertou que NÃO atrasaria\n",
        "# FP: Falso Positivo (Previu 1, Real 0) - Errou, previu que atrasaria, mas NÃO atrasou (alarme falso)\n",
        "# FN: Falso Negativo (Previu 0, Real 1) - Errou, previu que NÃO atrasaria, mas ATRASOU (o pior para SLA!)\n",
        "# TP: Verdadeiro Positivo (Previu 1, Real 1) - Acertou que atrasaria\n",
        "\n",
        "# Ajuste as coordenadas x,y para posicionar os textos na sua plotagem\n",
        "# Exemplo: plt.text(0.5, 1.2, 'FP (Falso Positivo)', transform=plt.gca().transAxes, horizontalalignment='center', color='red')\n",
        "# plt.text(0.5, -0.2, 'Verdadeiros Positivos (TP)', ha='center', va='center', fontsize=10, color='green', transform=plt.gca().transAxes)\n",
        "# plt.text(-0.2, 0.5, 'Falsos Positivos (FP)', ha='center', va='center', fontsize=10, color='red', transform=plt.gca().transAxes, rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nDetalhes da Matriz de Confusão:\")\n",
        "print(f\"Verdadeiros Negativos (TN): {cm[0,0]} (Previu 0, Real 0)\")\n",
        "print(f\"Falsos Positivos (FP): {cm[0,1]} (Previu 1, Real 0)\")\n",
        "print(f\"Falsos Negativos (FN): {cm[1,0]} (Previu 0, Real 1)\")\n",
        "print(f\"Verdadeiros Positivos (TP): {cm[1,1]} (Previu 1, Real 1)\")"
      ],
      "metadata": {
        "id": "q90ukB4JEdiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7° Passo para o TCC Salvar o Pipeline Treinado e Baixar para a Máquina Local ---\n",
        "\n",
        "# Nome do arquivo do modelo a ser salvo no ambiente Colab (e depois baixado)\n",
        "MODEL_SAVE_NAME = 'ML_certificado_V2.pkl'\n",
        "\n",
        "# Salvar o pipeline completo\n",
        "joblib.dump(model_pipeline, MODEL_SAVE_NAME)\n",
        "print(f\"\\nPipeline de ML salvo com sucesso no ambiente Colab como: {MODEL_SAVE_NAME}\")\n",
        "\n",
        "# Baixar o arquivo do modelo para sua máquina local\n",
        "print(f\"Fazendo download de '{MODEL_SAVE_NAME}' para sua máquina local...\")\n",
        "files.download(MODEL_SAVE_NAME)\n",
        "print(\"Download concluído!\")"
      ],
      "metadata": {
        "id": "4iV2b_f_ElFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Gráficos de Curva ROC e Precision-Recall ---\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "\n",
        "# As variáveis y_test e y_proba já foram calculadas na Célula 6\n",
        "# y_test: Valores reais (0 ou 1) do conjunto de teste\n",
        "# y_proba: Probabilidades previstas pelo modelo para a classe 1 (atrasado)\n",
        "\n",
        "# --- 1. Curva ROC (Receiver Operating Characteristic) ---\n",
        "print(\"\\nGerando Curva ROC...\")\n",
        "fpr, tpr, thresholds_roc = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr) # Já calculamos na Célula 6, mas podemos refazer aqui\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Classificador Aleatório')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taxa de Falsos Positivos (FPR)') # 1 - Especificidade\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (TPR) / Sensibilidade') # Recall\n",
        "plt.title('Curva ROC - Previsão de Atraso de SLA')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Interpretação da Curva ROC:\")\n",
        "print(f\"- A Curva ROC mostra a taxa de verdadeiros positivos (TPR) versus a taxa de falsos positivos (FPR) em vários limiares de classificação.\")\n",
        "print(f\"- A Área sob a Curva (AUC) de {roc_auc:.4f} é uma medida da capacidade do modelo de distinguir entre as classes. Um valor próximo de 1.0 indica um excelente poder discriminatório.\")\n",
        "print(f\"- Quanto mais a curva se afasta da linha diagonal (classificador aleatório), melhor o modelo.\")\n",
        "\n",
        "# --- 2. Curva Precision-Recall ---\n",
        "print(\"\\nGerando Curva Precision-Recall...\")\n",
        "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
        "avg_precision = average_precision_score(y_test, y_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(recall, precision, color='blue', lw=2, label=f'Curva Precision-Recall (AP = {avg_precision:.4f})')\n",
        "plt.xlabel('Recall (Sensibilidade)')\n",
        "plt.ylabel('Precisão')\n",
        "plt.title('Curva Precision-Recall - Previsão de Atraso de SLA')\n",
        "plt.legend(loc='lower left')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Interpretação da Curva Precision-Recall:\")\n",
        "print(f\"- A Curva Precision-Recall exibe a precisão e o recall do modelo em diferentes limiares. É especialmente útil quando há um desbalanceamento de classes, onde a classe positiva (atraso) é menos frequente.\")\n",
        "print(f\"- A Média de Precisão (AP) de {avg_precision:.4f} é a área sob a Curva Precision-Recall. Quanto maior o AP, melhor o modelo em identificar a classe positiva sem muitos falsos positivos.\")\n",
        "print(f\"- Um valor alto tanto para precisão quanto para recall ao longo da curva indica um modelo robusto.\")\n",
        "\n",
        "# --- Opcional: Gráfico de Probabilidade de Previsão vs Limiar (Threshold) ---\n",
        "# Este gráfico pode ajudar a escolher um limite de corte ideal para sua operação.\n",
        "# Exemplo: onde Precision e Recall se cruzam, ou onde há um bom equilíbrio.\n",
        "# Pode ser muito útil para o TCC para justificar a escolha do limite de 0.5 (ou outro).\n",
        "\n",
        "# F1-score para diferentes thresholds\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "f1_scores[f1_scores == float('inf')] = 0 # Trata divisão por zero (ocorre para recall=0)\n",
        "\n",
        "# Encontrar o melhor threshold para F1-score (ou para um equilíbrio específico)\n",
        "best_f1_threshold = thresholds_pr[f1_scores.argmax()]\n",
        "best_f1_score = f1_scores.max()\n",
        "print(f\"\\nMelhor Threshold para F1-score: {best_f1_threshold:.4f} (F1-score: {best_f1_score:.4f})\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(thresholds_pr, precision[:-1], label='Precisão') # precision[:-1] porque thresholds_pr tem um item a menos\n",
        "plt.plot(thresholds_pr, recall[:-1], label='Recall')\n",
        "plt.plot(thresholds_pr, f1_scores[:-1], label='F1-score', linestyle='--')\n",
        "plt.axvline(x=0.5, color='gray', linestyle=':', label='Threshold Padrão (0.5)')\n",
        "plt.axvline(x=best_f1_threshold, color='green', linestyle='--', label=f'Melhor F1 Threshold ({best_f1_threshold:.2f})')\n",
        "\n",
        "plt.xlabel('Limiar de Probabilidade (Threshold)')\n",
        "plt.ylabel('Métrica')\n",
        "plt.title('Precisão, Recall e F1-score vs. Limiar de Probabilidade')\n",
        "plt.legend(loc='best')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Interpretação da Escolha do Limiar (Threshold):\")\n",
        "print(f\"- O gráfico mostra como a Precisão, o Recall e o F1-score variam conforme o limiar de probabilidade para classificar um ticket como 'Atrasado (1)'.\")\n",
        "print(f\"- Um limiar de 0.5 é comumente usado por padrão, onde probabilidades > 0.5 são classificadas como '1'.\")\n",
        "print(f\"- A escolha do limiar ideal depende do custo dos erros: se evitar um 'Falso Negativo' (perder um atraso real) é mais crítico, pode-se escolher um limiar menor para aumentar o Recall. Se evitar um 'Falso Positivo' (alarme falso) é mais importante, pode-se escolher um limiar maior para aumentar a Precisão.\")"
      ],
      "metadata": {
        "id": "nimK2lfoYmd-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}